{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Тест\" data-toc-modified-id=\"Тест-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Тест</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Выводы</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для интернет-магазина"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Необходимо обучить модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Необходимо построить модель со значением метрики качества *F1* не меньше 0.75. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymystem3 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: requests in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from pymystem3) (2.28.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from requests->pymystem3) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from requests->pymystem3) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from requests->pymystem3) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from requests->pymystem3) (2022.6.15)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymystem3\n",
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (3.3.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy) (2.28.0)\n",
      "Requirement already satisfied: setuptools in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy) (62.6.0)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy) (0.4.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy) (1.0.7)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy) (0.9.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy) (2.4.3)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy) (8.0.17)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy) (4.64.0)\n",
      "Requirement already satisfied: jinja2 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy) (0.7.8)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy) (1.20.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy) (0.6.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (4.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: colorama in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "Collecting en-core-web-sm==3.3.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 12.8/12.8 MB 8.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from en-core-web-sm==3.3.0) (3.3.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.7)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.8.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.7.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.28.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.9.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.64.0)\n",
      "Requirement already satisfied: setuptools in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (62.6.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (21.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.6)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.17)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.9)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.6.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.20.1)\n",
      "Requirement already satisfied: jinja2 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.1.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.2.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.12)\n",
      "Requirement already satisfied: colorama in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\anaconda\\envs\\ds_practicum_env\\lib\\site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.1.1)\n",
      "[!] As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the full\n",
      "pipeline package name 'en_core_web_sm' instead.\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-11 21:29:06.852275: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-07-11 21:29:06.852296: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\taras\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\taras\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install spacy\n",
    "!{sys.executable} -m spacy download en\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np \n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier \n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re \n",
    "from tqdm import tqdm\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth1 = 'toxic_comments.csv'\n",
    "pth2 = '/datasets/toxic_comments.csv'\n",
    "\n",
    "if os.path.exists(pth1):\n",
    "    data = pd.read_csv(pth1)\n",
    "elif os.path.exists(pth2):\n",
    "    data = pd.read_csv(pth2)\n",
    "else:\n",
    "    print('Something is wrong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "toxic    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1131876717871444"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = data['toxic'].value_counts()\n",
    "s[1]/s[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем чистку, токенизацию и лемматизацию с помощью WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corp = data['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "s = r'[^a-zA-Z0-9]'\n",
    "for i in corp:\n",
    "    cleared = re.sub(s, \" \", i)\n",
    "    corpus.append(\" \". join(cleared.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizered(corpus):\n",
    "    corpus_lem = []\n",
    "    for i in corpus:\n",
    "        s = nlp(i)\n",
    "        corpus_lem.append(\" \".join([token.lemma_ for token in s]))\n",
    "    return corpus_lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['lemm_text']  = lemmatizered(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "соотношение классов в датасете corpus\n",
      " 0    89.736\n",
      "1    10.264\n",
      "Name: toxic, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "sample_size = 50000\n",
    "corpus = data.sample(n=sample_size,random_state=2007).reset_index(drop=True)\n",
    "print('соотношение классов в датасете corpus\\n', corpus.toxic.value_counts()/corpus.shape[0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wnl = WordNetLemmatizer()\n",
    "# def lemmatizered(corpus):\n",
    "#     corpus_lem = []\n",
    "#     for i in corpus:\n",
    "#         s = nltk.word_tokenize(i)\n",
    "#         corpus_lem.append(' '.join([wnl.lemmatize(k) for k in s]))\n",
    "#     return corpus_lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['lemm_text']  = lemmatizered(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В сете 2 столбца: toxic, text. Из них 90% нетоксичных комментариев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\taras\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = ['lemm_text']\n",
    "target = 'toxic'\n",
    "features = 'lemm_text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus, test_corpus = train_test_split(corpus, test_size = 0.2, random_state=2007,stratify = corpus['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2753</th>\n",
       "      <td>(It's true. You wikipedia kids need to get off...</td>\n",
       "      <td>1</td>\n",
       "      <td>it s true you wikipedia kid need to get off th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10360</th>\n",
       "      <td>If your referring to the comments on my talk p...</td>\n",
       "      <td>0</td>\n",
       "      <td>if your refer to the comment on my talk page I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31689</th>\n",
       "      <td>\"\\nHello  - I have no intention whatsoever of ...</td>\n",
       "      <td>0</td>\n",
       "      <td>hello I have no intention whatsoever of make W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49618</th>\n",
       "      <td>way.\\n\\nBut I think it's time to point out tha...</td>\n",
       "      <td>0</td>\n",
       "      <td>way but I think it s time to point out that th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22986</th>\n",
       "      <td>Hey daniel, this seems to be a large problem a...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey daniel this seem to be a large problem at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17767</th>\n",
       "      <td>Don't know what happened and not sure how to u...</td>\n",
       "      <td>0</td>\n",
       "      <td>Don t know what happen and not sure how to use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>Text is not small, it will take some time to r...</td>\n",
       "      <td>0</td>\n",
       "      <td>text be not small it will take some time to re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26300</th>\n",
       "      <td>Section titled ==Journeyperson== \\n\\nActually,...</td>\n",
       "      <td>0</td>\n",
       "      <td>section title Journeyperson Actually it be jus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13492</th>\n",
       "      <td>A message from Jasonceyre \\n\\n   f uc k you ho...</td>\n",
       "      <td>1</td>\n",
       "      <td>a message from Jasonceyre f uc k you hoe you a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>Sock puppetry \\n\\nPlease see the talk page his...</td>\n",
       "      <td>0</td>\n",
       "      <td>Sock puppetry please see the talk page history...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  toxic  \\\n",
       "2753   (It's true. You wikipedia kids need to get off...      1   \n",
       "10360  If your referring to the comments on my talk p...      0   \n",
       "31689  \"\\nHello  - I have no intention whatsoever of ...      0   \n",
       "49618  way.\\n\\nBut I think it's time to point out tha...      0   \n",
       "22986  Hey daniel, this seems to be a large problem a...      0   \n",
       "...                                                  ...    ...   \n",
       "17767  Don't know what happened and not sure how to u...      0   \n",
       "6043   Text is not small, it will take some time to r...      0   \n",
       "26300  Section titled ==Journeyperson== \\n\\nActually,...      0   \n",
       "13492  A message from Jasonceyre \\n\\n   f uc k you ho...      1   \n",
       "990    Sock puppetry \\n\\nPlease see the talk page his...      0   \n",
       "\n",
       "                                               lemm_text  \n",
       "2753   it s true you wikipedia kid need to get off th...  \n",
       "10360  if your refer to the comment on my talk page I...  \n",
       "31689  hello I have no intention whatsoever of make W...  \n",
       "49618  way but I think it s time to point out that th...  \n",
       "22986  hey daniel this seem to be a large problem at ...  \n",
       "...                                                  ...  \n",
       "17767  Don t know what happen and not sure how to use...  \n",
       "6043   text be not small it will take some time to re...  \n",
       "26300  section title Journeyperson Actually it be jus...  \n",
       "13492  a message from Jasonceyre f uc k you hoe you a...  \n",
       "990    Sock puppetry please see the talk page history...  \n",
       "\n",
       "[40000 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = count_tf_idf.fit_transform(train_corpus['lemm_text'])\n",
    "features_test = count_tf_idf.transform(test_corpus['lemm_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train = train_corpus['toxic']\n",
    "target_test = test_corpus['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 72354)\n",
      "(10000, 72354)\n",
      "(40000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(features_train.shape)\n",
    "print(features_test.shape)\n",
    "print(target_train.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовили данные, выделили фичи и таргеты, после лемматизации и чистки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(class_weight='balanced', \n",
    "                        random_state=2007,\n",
    "                        n_jobs=-1,\n",
    "                        solver='liblinear'\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_params = {\"max_iter\":[10,50,10],\n",
    "             'C': [0.1, 1, 10],\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=LogisticRegression(class_weight='balanced', n_jobs=-1,\n",
       "                                          random_state=2007,\n",
       "                                          solver='liblinear'),\n",
       "             param_grid={'C': [0.1, 1, 10], 'max_iter': [10, 50, 10]},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_gsearch = GridSearchCV(LR, LR_params, scoring='f1', cv=5)\n",
    "LR_gsearch.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'max_iter': 10}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_gsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.754341463307493"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_gsearch.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CatBoost - очень долгая, можно попробовать уменьшить выборку в n раз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# CB_model = CatBoostClassifier(random_state = 2007)\n",
    "# CB_param_search = { \n",
    "#                     'learning_rate': [0.03, 0.1],\n",
    "#                     'depth': [4, 6, 10]\n",
    "# }\n",
    "# CB_gsearch = GridSearchCV(n_jobs = -1, estimator=CB_model, cv=3, param_grid=CB_param_search, scoring = 'f1')\n",
    "\n",
    "# CB_gsearch.fit(features_train, target_train, verbose=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CB_gsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "CB = CatBoostClassifier( \n",
    "    text_features=text_features,\n",
    "    verbose=100,\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='F1',\n",
    "    task_type=\"GPU\",\n",
    "    iterations=1000,\n",
    "    learning_rate=0.2,\n",
    "    random_seed = 2007,\n",
    "    auto_class_weights = 'Balanced',\n",
    "    text_processing = {\n",
    "        \"tokenizers\" : [{\n",
    "            \"tokenizer_id\" : \"Space\",\n",
    "            \"separator_type\" : \"ByDelimiter\",\n",
    "            \"delimiter\" : \" \"\n",
    "        }],\n",
    "\n",
    "        \"dictionaries\" : [{\n",
    "            \"dictionary_id\" : \"BiGram\",\n",
    "            \"token_level_type\": \"Letter\",\n",
    "            \"max_dictionary_size\" : \"150000\",\n",
    "            \"occurrence_lower_bound\" : \"1\",\n",
    "            \"gram_order\" : \"2\"\n",
    "        },{\n",
    "            \"dictionary_id\" : \"Trigram\",\n",
    "            \"max_dictionary_size\" : \"150000\",\n",
    "            \"token_level_type\": \"Letter\",\n",
    "            \"occurrence_lower_bound\" : \"1\",\n",
    "            \"gram_order\" : \"3\"\n",
    "        }],\n",
    "\n",
    "        \"feature_processing\" : {\n",
    "            \"default\" : [\n",
    "                    {\n",
    "                    \"dictionaries_names\" : [\"BiGram\", \"Trigram\"],\n",
    "                    \"feature_calcers\" : [\"BoW\"],\n",
    "                    \"tokenizers_names\" : [\"Space\"]\n",
    "                },\n",
    "                    {\n",
    "                \"dictionaries_names\" : [\"BiGram\", \"Trigram\"],\n",
    "                \"feature_calcers\" : [\"NaiveBayes\"],\n",
    "                \"tokenizers_names\" : [\"Space\"]\n",
    "            },{\n",
    "                \"dictionaries_names\" : [ \"BiGram\", \"Trigram\"],\n",
    "                \"feature_calcers\" : [\"BM25\"],\n",
    "                \"tokenizers_names\" : [\"Space\"]\n",
    "            },\n",
    "            ],\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17e91f4520bf4b7a9278b0f9fa45e662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8019772\ttest: 0.8122097\tbest: 0.8122097 (0)\ttotal: 46.2ms\tremaining: 46.2s\n",
      "100:\tlearn: 0.8967984\ttest: 0.8653464\tbest: 0.8653464 (100)\ttotal: 3.9s\tremaining: 34.7s\n",
      "200:\tlearn: 0.9210980\ttest: 0.8637332\tbest: 0.8723728 (135)\ttotal: 7.74s\tremaining: 30.8s\n",
      "300:\tlearn: 0.9336392\ttest: 0.8655891\tbest: 0.8723728 (135)\ttotal: 11.6s\tremaining: 26.9s\n",
      "400:\tlearn: 0.9413552\ttest: 0.8652908\tbest: 0.8723728 (135)\ttotal: 15.5s\tremaining: 23.1s\n",
      "500:\tlearn: 0.9489553\ttest: 0.8647845\tbest: 0.8723728 (135)\ttotal: 19.4s\tremaining: 19.3s\n",
      "600:\tlearn: 0.9561321\ttest: 0.8643505\tbest: 0.8723728 (135)\ttotal: 23.5s\tremaining: 15.6s\n",
      "700:\tlearn: 0.9617361\ttest: 0.8573306\tbest: 0.8723728 (135)\ttotal: 27.4s\tremaining: 11.7s\n",
      "800:\tlearn: 0.9690470\ttest: 0.8504691\tbest: 0.8723728 (135)\ttotal: 31.4s\tremaining: 7.8s\n",
      "900:\tlearn: 0.9724066\ttest: 0.8504365\tbest: 0.8723728 (135)\ttotal: 35.2s\tremaining: 3.87s\n",
      "999:\tlearn: 0.9770365\ttest: 0.8466743\tbest: 0.8723728 (135)\ttotal: 39.1s\tremaining: 0us\n",
      "bestTest = 0.8723728375\n",
      "bestIteration = 135\n",
      "Shrink model to first 136 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1ff88d8d640>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CB.fit(\n",
    "    train_corpus[text_features], train_corpus[target],\n",
    "    eval_set=(test_corpus[text_features], test_corpus[target]),\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full = corpus.sample(frac=0.8, random_state=2007).copy()\n",
    "test = corpus[~corpus.index.isin(train_full.index)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_full_tf = train_full[['lemm_text','toxic']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "CB2 = CatBoostClassifier(verbose = 100,\n",
    "                        learning_rate=0.7,\n",
    "                        early_stopping_rounds=200,\n",
    "                        eval_metric='AUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.8126666\tbest: 0.8126666 (0)\ttotal: 38.9ms\tremaining: 38.8s\n",
      "100:\ttest: 0.9582289\tbest: 0.9587021 (74)\ttotal: 5.6s\tremaining: 49.8s\n",
      "200:\ttest: 0.9548237\tbest: 0.9587021 (74)\ttotal: 11.2s\tremaining: 44.5s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.9587021343\n",
      "bestIteration = 74\n",
      "\n",
      "Shrink model to first 75 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1ff85fa78b0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CB2.fit(train_full_tf[['lemm_text']], train_full_tf[['toxic']],\n",
    "       eval_set=(test[['lemm_text']], test[['toxic']]),\n",
    "       text_features=['lemm_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=RandomForestClassifier(class_weight='balanced',\n",
       "                                              n_jobs=-1),\n",
       "             param_grid={'max_depth': [13, 14], 'n_estimators': [100]},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Forest = RandomForestClassifier(class_weight='balanced', n_jobs=-1 )\n",
    "forest_params = { 'n_estimators': [100],\n",
    "                    'max_depth' : [i for i in range(13,15)]\n",
    "                }\n",
    "forest_gsearch = GridSearchCV(Forest, forest_params, scoring='f1', cv=5)\n",
    "forest_gsearch.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 13, 'n_estimators': 100}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_gsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38713036182376187"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_gsearch.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LGBMClassifier(random_state=2007), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.1],\n",
       "                         'max_depth': [8, 9, 10, 11, 12, 13, 14],\n",
       "                         'n_estimators': [200]},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGBM_model = LGBMClassifier(random_state = 2007)\n",
    "LGBM_params = {\n",
    "  'n_estimators': [200],\n",
    "  'learning_rate': [0.01, 0.1],\n",
    "  'max_depth': [i for i in range(8,15)]}\n",
    "\n",
    "LGBM_gsearch = GridSearchCV(n_jobs = -1, estimator=LGBM_model, cv=5, param_grid=LGBM_params, scoring = 'f1')\n",
    "\n",
    "LGBM_gsearch.fit(features_train, target_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_depth': 14, 'n_estimators': 200}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGBM_gsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7221131141460556"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGBM_gsearch.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CatBoost 2 модели с параметрами и без"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тест"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7580645161290323"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_test = LogisticRegression(class_weight='balanced',\n",
    "                             C = 10,\n",
    "                        random_state=2007,\n",
    "                        n_jobs=-1,\n",
    "                        solver='liblinear',\n",
    "                        max_iter = 10\n",
    "                       )\n",
    "LR_test.fit(features_train, target_train)\n",
    "LR_pred = LR_test.predict(features_test)\n",
    "LR_F1 = f1_score(target_test, LR_pred)\n",
    "LR_F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3967916961547535"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Forest_test = RandomForestClassifier(class_weight='balanced',\n",
    "                                 random_state=2007,\n",
    "                                 n_jobs=-1,\n",
    "                                 max_depth =14,\n",
    "                                 n_estimators = 100\n",
    "                       )\n",
    "Forest_test.fit(features_train, target_train)\n",
    "Forest_pred = Forest_test.predict(features_test)\n",
    "Forest_F1 = f1_score(target_test, Forest_pred)\n",
    "Forest_F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6427703523693803"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGBM_test = LGBMClassifier(class_weight='balanced',\n",
    "                           random_state=2007,\n",
    "                                   n_jobs=-1,\n",
    "                                   n_estimators = 200,\n",
    "                                   learning_rate=0.01,\n",
    "                                   max_depth=4,\n",
    "                                   )\n",
    "LGBM_test.fit(features_train, target_train)\n",
    "LGBM_pred = LGBM_test.predict(features_test)\n",
    "LGBM_F1 = f1_score(target_test, LGBM_pred)\n",
    "LGBM_F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.657471264367816"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CBT = f1_score(CB.predict(test_corpus[text_features]),test_corpus[target])\n",
    "CBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7618522601984565"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CBT2 = f1_score(CB2.predict(test[['lemm_text']]),test[['toxic']])\n",
    "CBT2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшей моделью оказалась LogisticRegression, CatBoost только они удовлетворяет порогу в 0.75 f1 метрики.\n"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1185,
    "start_time": "2022-06-28T14:44:14.658Z"
   },
   {
    "duration": 1357,
    "start_time": "2022-06-28T17:45:45.892Z"
   },
   {
    "duration": 2250,
    "start_time": "2022-06-28T17:45:48.201Z"
   },
   {
    "duration": 28,
    "start_time": "2022-06-28T17:45:50.464Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-28T17:45:50.494Z"
   },
   {
    "duration": 23,
    "start_time": "2022-06-28T17:45:50.509Z"
   },
   {
    "duration": 31,
    "start_time": "2022-06-28T17:45:50.533Z"
   },
   {
    "duration": 2,
    "start_time": "2022-06-28T17:45:54.288Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-28T17:46:42.638Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-28T17:51:47.528Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-28T17:51:50.340Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-28T17:52:15.147Z"
   },
   {
    "duration": 128,
    "start_time": "2022-06-28T17:52:34.303Z"
   },
   {
    "duration": 38506,
    "start_time": "2022-06-28T17:52:53.816Z"
   },
   {
    "duration": 62,
    "start_time": "2022-06-28T17:53:52.805Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-28T17:55:01.566Z"
   },
   {
    "duration": 2238,
    "start_time": "2022-06-28T17:58:46.671Z"
   },
   {
    "duration": 1377,
    "start_time": "2022-06-28T17:58:48.911Z"
   },
   {
    "duration": 802,
    "start_time": "2022-06-28T17:58:50.290Z"
   },
   {
    "duration": 24,
    "start_time": "2022-06-28T17:58:51.094Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-28T17:58:51.120Z"
   },
   {
    "duration": 45,
    "start_time": "2022-06-28T17:58:51.134Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-28T17:58:51.181Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-28T17:58:51.205Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-28T17:58:51.211Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-28T17:58:51.217Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-28T17:58:51.223Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-28T17:58:51.230Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-28T17:58:53.067Z"
   },
   {
    "duration": 2,
    "start_time": "2022-06-28T17:59:08.817Z"
   },
   {
    "duration": 37786,
    "start_time": "2022-06-28T17:59:09.099Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-28T17:59:54.107Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-28T18:00:23.646Z"
   },
   {
    "duration": 58,
    "start_time": "2022-06-28T18:00:33.751Z"
   },
   {
    "duration": 2014,
    "start_time": "2022-06-28T18:17:49.964Z"
   },
   {
    "duration": 1396,
    "start_time": "2022-06-28T18:17:51.980Z"
   },
   {
    "duration": 827,
    "start_time": "2022-06-28T18:17:53.378Z"
   },
   {
    "duration": 29,
    "start_time": "2022-06-28T18:17:54.208Z"
   },
   {
    "duration": 28,
    "start_time": "2022-06-28T18:17:54.238Z"
   },
   {
    "duration": 29,
    "start_time": "2022-06-28T18:17:54.269Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-28T18:17:54.300Z"
   },
   {
    "duration": 2,
    "start_time": "2022-06-28T18:17:54.307Z"
   },
   {
    "duration": 2,
    "start_time": "2022-06-28T18:17:54.540Z"
   },
   {
    "duration": 2,
    "start_time": "2022-06-28T18:17:54.728Z"
   },
   {
    "duration": 127,
    "start_time": "2022-06-28T18:17:55.418Z"
   },
   {
    "duration": 2,
    "start_time": "2022-06-28T18:18:30.215Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-28T18:18:36.521Z"
   },
   {
    "duration": 4085,
    "start_time": "2022-06-28T18:20:30.864Z"
   },
   {
    "duration": 3901,
    "start_time": "2022-06-28T18:20:41.231Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-28T18:20:47.015Z"
   },
   {
    "duration": 30,
    "start_time": "2022-06-28T18:21:27.233Z"
   },
   {
    "duration": 20,
    "start_time": "2022-06-28T18:21:30.314Z"
   },
   {
    "duration": 54,
    "start_time": "2022-06-28T18:30:43.292Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-28T18:31:20.538Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-28T18:31:33.606Z"
   },
   {
    "duration": 84538,
    "start_time": "2022-06-28T18:31:50.623Z"
   },
   {
    "duration": 2284,
    "start_time": "2022-06-28T18:34:34.704Z"
   },
   {
    "duration": 1705,
    "start_time": "2022-06-28T18:34:36.991Z"
   },
   {
    "duration": 880,
    "start_time": "2022-06-28T18:34:38.698Z"
   },
   {
    "duration": 30,
    "start_time": "2022-06-28T18:34:39.581Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-28T18:34:39.613Z"
   },
   {
    "duration": 45,
    "start_time": "2022-06-28T18:34:39.627Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-28T18:34:39.674Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-28T18:34:39.686Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-28T18:34:39.692Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-28T18:34:39.710Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-28T18:34:39.718Z"
   },
   {
    "duration": 3946,
    "start_time": "2022-06-28T18:34:39.734Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-28T18:34:43.682Z"
   },
   {
    "duration": 2004,
    "start_time": "2022-06-28T18:35:04.066Z"
   },
   {
    "duration": 1447,
    "start_time": "2022-06-28T18:35:06.073Z"
   },
   {
    "duration": 814,
    "start_time": "2022-06-28T18:35:07.522Z"
   },
   {
    "duration": 35,
    "start_time": "2022-06-28T18:35:08.338Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-28T18:35:08.375Z"
   },
   {
    "duration": 28,
    "start_time": "2022-06-28T18:35:08.389Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-28T18:35:08.419Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-28T18:35:08.428Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-28T18:35:08.458Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-28T18:35:08.465Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-28T18:35:08.473Z"
   },
   {
    "duration": 3866,
    "start_time": "2022-06-28T18:35:08.483Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-28T18:35:12.351Z"
   },
   {
    "duration": 2012,
    "start_time": "2022-06-28T18:35:44.770Z"
   },
   {
    "duration": 1356,
    "start_time": "2022-06-28T18:35:46.784Z"
   },
   {
    "duration": 831,
    "start_time": "2022-06-28T18:35:48.149Z"
   },
   {
    "duration": 26,
    "start_time": "2022-06-28T18:35:48.982Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-28T18:35:49.010Z"
   },
   {
    "duration": 43,
    "start_time": "2022-06-28T18:35:49.023Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-28T18:35:49.068Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-28T18:35:49.079Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-28T18:35:49.084Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-28T18:35:49.093Z"
   },
   {
    "duration": 29,
    "start_time": "2022-06-28T18:35:49.104Z"
   },
   {
    "duration": 3830,
    "start_time": "2022-06-28T18:35:49.135Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-28T18:35:52.966Z"
   },
   {
    "duration": 79197,
    "start_time": "2022-06-28T18:35:52.971Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-28T18:37:12.171Z"
   },
   {
    "duration": 127,
    "start_time": "2022-06-28T18:37:12.185Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T18:37:12.314Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T18:37:12.316Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T18:37:12.317Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T18:37:12.318Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T18:37:12.319Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T18:37:12.321Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T18:37:12.322Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T18:37:12.323Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T18:37:12.324Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T18:37:12.325Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T18:37:12.326Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T18:37:12.327Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T18:37:12.328Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T18:37:12.352Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T18:37:12.356Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T18:37:12.357Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T18:37:12.358Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T18:37:12.359Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T18:37:12.359Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T18:37:12.360Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T18:37:12.361Z"
   },
   {
    "duration": 1,
    "start_time": "2022-06-28T18:37:12.362Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T18:37:12.363Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T18:37:12.364Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T18:37:12.365Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-28T18:40:34.401Z"
   },
   {
    "duration": 2,
    "start_time": "2022-06-28T18:41:28.597Z"
   },
   {
    "duration": 133,
    "start_time": "2022-06-28T18:41:52.644Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-28T18:41:53.301Z"
   },
   {
    "duration": 32,
    "start_time": "2022-06-28T18:41:54.213Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-28T18:41:55.226Z"
   },
   {
    "duration": 7477,
    "start_time": "2022-06-28T18:41:56.492Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-28T18:42:03.971Z"
   },
   {
    "duration": 2,
    "start_time": "2022-06-28T18:42:13.482Z"
   },
   {
    "duration": 2,
    "start_time": "2022-06-28T18:42:13.511Z"
   },
   {
    "duration": 1183632,
    "start_time": "2022-06-28T18:42:13.543Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-28T19:01:57.177Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-28T19:01:57.183Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-28T19:01:57.192Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-28T19:01:57.199Z"
   },
   {
    "duration": 271165,
    "start_time": "2022-06-28T19:01:57.207Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-28T19:06:28.375Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-28T19:06:28.381Z"
   },
   {
    "duration": 1933,
    "start_time": "2022-06-28T19:57:23.239Z"
   },
   {
    "duration": 1485,
    "start_time": "2022-06-28T19:57:25.175Z"
   },
   {
    "duration": 792,
    "start_time": "2022-06-28T19:57:26.662Z"
   },
   {
    "duration": 27,
    "start_time": "2022-06-28T19:57:27.456Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-28T19:57:27.485Z"
   },
   {
    "duration": 38,
    "start_time": "2022-06-28T19:57:27.497Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-28T19:57:27.537Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-28T19:57:27.555Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-28T19:57:27.578Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-28T19:57:27.587Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-28T19:57:27.592Z"
   },
   {
    "duration": 3803,
    "start_time": "2022-06-28T19:57:27.602Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-28T19:57:31.406Z"
   },
   {
    "duration": 79549,
    "start_time": "2022-06-28T19:57:31.411Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-28T19:58:50.962Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-28T19:58:50.972Z"
   },
   {
    "duration": 160,
    "start_time": "2022-06-28T19:58:50.979Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-28T19:58:51.140Z"
   },
   {
    "duration": 38,
    "start_time": "2022-06-28T19:58:51.145Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-28T19:58:51.185Z"
   },
   {
    "duration": 2580,
    "start_time": "2022-06-28T19:58:51.189Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T19:58:53.792Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T19:58:53.793Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T19:58:53.795Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T19:58:53.796Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T19:58:53.798Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T19:58:53.799Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T19:58:53.801Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T19:58:53.802Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T19:58:53.804Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T19:58:53.805Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T19:58:53.806Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T19:58:53.808Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T19:58:53.809Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T19:58:53.811Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T19:58:53.812Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T19:58:53.813Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T19:58:53.854Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T19:58:53.855Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-28T19:58:53.856Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-29T09:11:16.578Z"
   },
   {
    "duration": 1847,
    "start_time": "2022-06-29T09:11:22.994Z"
   },
   {
    "duration": 3260,
    "start_time": "2022-06-29T09:11:24.843Z"
   },
   {
    "duration": 44,
    "start_time": "2022-06-29T09:11:28.104Z"
   },
   {
    "duration": 33,
    "start_time": "2022-06-29T09:11:28.153Z"
   },
   {
    "duration": 32,
    "start_time": "2022-06-29T09:11:28.188Z"
   },
   {
    "duration": 24,
    "start_time": "2022-06-29T09:11:28.221Z"
   },
   {
    "duration": 2,
    "start_time": "2022-06-29T09:11:34.585Z"
   },
   {
    "duration": 4612,
    "start_time": "2022-06-29T09:11:38.067Z"
   },
   {
    "duration": 47,
    "start_time": "2022-06-29T09:11:51.760Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-29T09:11:56.319Z"
   },
   {
    "duration": 2,
    "start_time": "2022-06-29T09:13:18.985Z"
   },
   {
    "duration": 43,
    "start_time": "2022-06-29T09:13:26.210Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-29T09:13:31.377Z"
   },
   {
    "duration": 163,
    "start_time": "2022-06-29T09:13:56.283Z"
   },
   {
    "duration": 149,
    "start_time": "2022-06-29T09:14:00.358Z"
   },
   {
    "duration": 1505,
    "start_time": "2022-06-29T09:14:08.292Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-29T09:15:19.444Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-29T09:15:29.474Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-29T09:15:33.459Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-29T09:15:38.854Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-29T09:18:40.204Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-29T09:19:02.064Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-29T09:19:08.110Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-29T09:19:49.359Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-29T09:21:57.592Z"
   },
   {
    "duration": 89608,
    "start_time": "2022-06-29T09:21:58.710Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-29T09:23:28.320Z"
   },
   {
    "duration": 223,
    "start_time": "2022-06-29T09:23:28.338Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-29T09:23:28.563Z"
   },
   {
    "duration": 46,
    "start_time": "2022-06-29T09:23:28.567Z"
   },
   {
    "duration": 2,
    "start_time": "2022-06-29T09:23:28.615Z"
   },
   {
    "duration": 7849,
    "start_time": "2022-06-29T09:23:28.619Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-29T09:23:36.470Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-29T09:23:36.477Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-29T09:23:36.488Z"
   },
   {
    "duration": 1220454,
    "start_time": "2022-06-29T09:23:36.496Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-29T09:43:56.951Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-29T09:43:56.956Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-29T09:43:56.969Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-29T09:43:56.974Z"
   },
   {
    "duration": 294523,
    "start_time": "2022-06-29T09:43:56.983Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-29T09:48:51.508Z"
   },
   {
    "duration": 27,
    "start_time": "2022-06-29T09:48:51.513Z"
   },
   {
    "duration": 97,
    "start_time": "2022-06-29T11:54:58.582Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
